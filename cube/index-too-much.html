<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  <title>CUBE: Collaborative Multi-Agent Block-Pushing Environment</title>
  <meta name="description" content="CUBE is a lightweight, scalable, and interpretable environment for collective planning and cooperative evaluation of LLM and RL agents."/>
  <meta name="keywords" content="CUBE, multi-agent, block pushing, LLM agents, symbolic planning, reinforcement learning, PettingZoo, cooperative planning" />

  <meta property="og:title" content="CUBE: Collaborative Multi-Agent Block-Pushing Environment" />
  <meta property="og:description" content="A scalable environment blending symbolic actions and embodied interaction for cooperative agents." />
  <meta property="og:url" content="https://happyeureka.github.io/cube/" />
  <meta property="og:image" content="static/images/banner_cube.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />

  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="CUBE: Collaborative Multi-Agent Block-Pushing Environment" />
  <meta name="twitter:description" content="Lightweight, scalable benchmark for cooperative LLM and RL agents with symbolic plus primitive actions." />
  <meta name="twitter:image" content="static/images/banner_cube_twitter.png" />

  <link href="https://fonts.googleapis.com/css?family=Google+Sans:400,500,700|Noto+Sans:400,700|Castoro:400,700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="static/css/bulma.min.css" />
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
  <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="static/css/index.css" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero is-light">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              CUBE: Collaborative Multi-Agent Block-Pushing Environment for Collective Planning with LLM Agents
            </h1>

            <h2 class="subtitle is-4">
              A PettingZoo compatible grid world where symbolic plans are grounded in embodied interaction,
              with a single parameter n that controls team size, block spectrum, and task difficulty.
            </h2>

            <p class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://happyeureka.github.io/" target="_blank">Hanqing Yang</a><sup>*1</sup>,
              </span>
              <span class="author-block">
                <a href="https://narjesnourzad.wixsite.com/webpage" target="_blank">Narjes Nourzad</a><sup>*†2</sup>,
              </span>
              <span class="author-block">
                <a href="https://github.com/13RENDA" target="_blank">Shiyu Chen</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.andrew.cmu.edu/user/cjoewong/" target="_blank">Carlee Joe-Wong</a><sup>1</sup>
              </span>
            </p>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup><a href="https://www.cmu.edu/" target="_blank">Carnegie Mellon University</a><br>
                <sup>2</sup><a href="https://www.usc.edu/" target="_blank">University of Southern California</a><br>
                NeurIPS 2025 Workshop: Scaling Environments for Agents (SEA)
              </span>
              <span class="eql-cntrb">
                <small><br><sup>*</sup>Equal Contribution &nbsp;&nbsp; <sup>†</sup> Work done during an internship at Carnegie Mellon University</small>
              </span>
            </div>

            <div class="publication-links" style="margin-top:1rem">
              <span class="link-block">
                <a href="#" target="_blank" class="external-link button is-normal is-rounded is-light">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code (soon)</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://openreview.net/pdf?id=T7OoS6t11c" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="static/pdfs/cube_poster.pdf" target="_blank" class="external-link button is-normal is-rounded is-light">
                  <span class="icon"><i class="far fa-file-pdf"></i></span>
                  <span>Poster</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div style="width:100%; max-height:520px; overflow:hidden; display:flex; justify-content:center; align-items:center;">
          <img src="static/videos/teaser.gif" alt="CUBE Teaser"
               style="width:auto; height:520px; object-fit:cover; object-position:center 50%;" />
        </div>
        <h2 style="margin-top:1rem">
          CUBE is a grid world where teams push weighted blocks into a goal zone while respecting embodied constraints.
          A single scaling parameter <em>n</em> jointly sets team size, block weights, and grid size, creating a transparent
          curriculum from small to large scale cooperation. Each panel illustrates a snapshot of a cooperative block pushing
          scenario at increasing scales (<em>n</em> from 2 to 256) under a simple <strong><em>always move right</em></strong> policy.
        </h2>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">What is CUBE</h2>
          <div class="content has-text-justified">
            <p>
              CUBE is a lightweight, portable, and scalable multi agent environment that unifies
              symbolic reasoning with embodied interaction. Agents operate in a shared grid world and must
              push weighted blocks into a goal zone while avoiding collisions, congestion, and unproductive block chains.
              These spatial dependencies make cooperation necessary and observable.
            </p>

            <p>
              At its base level CUBE is built on the PettingZoo parallel API, so it can plug directly into
              existing multi agent reinforcement learning pipelines. The default episode configuration is generated
              automatically from a single integer <code>n</code>. The grid side length is
              <code>k = max(20, n)</code>, there are <code>n</code> agents, and blocks have integer weights from
              <code>⌊n/2⌋ + 1</code> down to one, with lighter blocks appearing in greater numbers. Roughly half of the grid
              is covered by blocks. Agents start along the wall opposite the goal region, and blocks are placed away from
              walls and corners so that every block is movable by pushing.
            </p>

            <p>
              The parameter <code>n</code> therefore sets both environment scale and cooperative difficulty.
              As <code>n</code> increases, heavier blocks require larger agent quorums and more complex block chains,
              and congestion grows since each agent contributes only unit force. Tasks at the same <code>n</code> have
              comparable complexity, which supports fair comparison of cooperative strategies across methods.
            </p>

            <ul>
              <li>
                <strong>Embodied multi agent cooperation.</strong>
                Agents share a grid, occupy discrete cells, and exert one unit of force when they move.
                Blocks have weights proportional to their side length and can be pushed from any face.
                When agents align on a block face, their forces combine to move the block or a chain of blocks.
              </li>
              <li>
                <strong>Dual layer design.</strong>
                CUBE couples a symbolic layer and a vector based layer for observation, action, and feedback.
                Symbolic plans are executed as sequences of primitive movements, while the environment returns both
                low level state and structured symbolic feedback that summarize progress and outcomes.
              </li>
              <li>
                <strong>Controllable curriculum.</strong>
                A single parameter <code>n</code> sets grid size, agent count, and block distribution.
                Larger <code>n</code> increases the effort required for cooperative success while keeping
                difficulty predictable and reproducible.
              </li>
              <li>
                <strong>Lightweight environment.</strong>
                CUBE is implemented in Python with Numba acceleration and maintains low runtime and memory usage
                even with hundreds of agents, so environment cost stays small compared with LLM inference.
              </li>
            </ul>

            <figure class="image" style="margin-bottom: 1.25rem;">
              <img src="static/images/cube_overall.jpg" alt="CUBE overview and scaling diagram" />
            </figure>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Environment at a glance</h2>
          <div class="content has-text-justified">
            <p>
              CUBE is presented with four main contributions.
            </p>
            <ul>
              <li>
                <strong>Scalable environment.</strong> A lightweight, portable environment that supports variation
                in both number of agents and task difficulty.
              </li>
              <li>
                <strong>Reproducible curriculum.</strong> A difficulty curriculum governed by a single parameter
                <code>n</code> that enables systematic study of cooperation across comparable difficulty levels while
                still allowing custom scenarios.
              </li>
              <li>
                <strong>Dual interface.</strong> A paired symbolic and vector based interface for observation,
                action, and feedback that supports reinforcement learning agents, LLM agents, and hybrids.
              </li>
              <li>
                <strong>Baseline and scalability study.</strong> Empirical evaluation that profiles runtime,
                memory, and CPU usage, and compares heuristic and LLM based planners.
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns">
        <div class="column">
          <h2 class="title is-3">Why CUBE</h2>
          <div class="content has-text-justified">
            <p>
              Traditional reinforcement learning benchmarks emphasize low level action spaces and scalar rewards.
              These signals are useful for gradient based training but give little support for symbolic reasoning,
              interpretability, or debugging. For LLM agents, emitting long sequences of primitive moves and waiting
              for numerical rewards is unnatural and inefficient.
            </p>
            <p>
              Symbolic planning domains have clear preconditions and effects but usually assume deterministic
              transitions and ignore embodied dynamics such as collisions, congestion, or force accumulation.
              They are therefore not enough on their own to study embodied LLM agents that must reason in
              uncertain, interactive worlds.
            </p>
            <p>
              CUBE bridges this gap by wrapping primitive block pushing actions into a symbolic vocabulary and
              linking that vocabulary to an embodied grid world. This lets LLM agents plan using interpretable,
              compositional actions while still having to cope with uncertainty, races for cells, and changing geometry.
            </p>
          </div>
        </div>

        <div class="column">
          <h2 class="title is-4">Why embodied tasks</h2>
          <div class="content has-text-justified">
            <p>
              Human reasoning blends symbolic and embodied perspectives. We imagine plans, act, compare outcomes with
              expectations, and revise our internal models. CUBE is built to support a similar loop for LLM agents.
              Plans are expressed in symbolic actions, executed as primitive moves, and evaluated with both scalar
              and structured feedback.
            </p>
            <p>
              Embodied constraints keep tasks challenging as team size increases. Moving any block or agent reshapes
              the scene. Agents must cope with tasks that can disappear, delivery paths that become blocked by other
              blocks, and sequences where one agent can temporarily make a block unreachable.
            </p>
            <p>
              This makes CUBE a natural testbed for research on cooperative intelligence at scale, including
              communication, task allocation, and group level planning.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Embodied Constraints in CUBE</h2>
      <div class="columns is-vcentered">
        <div class="column is-half">
          <div class="content has-text-justified">
            <ul>
              <li>
                <strong>Discrete occupancy.</strong>
                Agents and blocks live on grid cells, one entity per cell.
              </li>
              <li>
                <strong>Forces and weights.</strong>
                Each agent exerts one unit of force in its movement direction.
                Each block has integer weight equal to the force needed to move it,
                and occupies a square whose side length equals that weight.
              </li>
              <li>
                <strong>Block chains.</strong>
                When blocks sit in front of one another along a push direction they form a chain.
                The chain moves as a composite object when total applied force at the leading face
                meets or exceeds the sum of weights of all blocks and all destination cells are free.
              </li>
              <li>
                <strong>Agent chains.</strong>
                When agents line up behind a block and push in the same direction,
                the effective force equals the number of aligned agents. If this meets the chain weight,
                the block chain and agents advance together; otherwise nothing moves.
              </li>
              <li>
                <strong>Collisions and races.</strong>
                Agent moves that target occupied cells fail. When several agents aim at the same free cell,
                the agent with smallest index claims it. This creates cell access races where one agent succeeds
                and others must rethink their plans.
              </li>
            </ul>
          </div>
        </div>

        <div class="column is-half has-text-centered">
          <figure class="image">
            <img src="static/images/succ_chain.png" alt="Illustration of embodied constraints" />
          </figure>
          <figure class="image">
            <img src="static/images/fail_chain.png" alt="Illustration of embodied constraints" />
          </figure>
          <p class="subtitle is-size-6">
            Agent chains, block chains, and forces in CUBE.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Observation, Action, and Feedback Interfaces</h2>
      <div class="columns is-vcentered">
        <div class="column is-half has-text-centered">
          <figure class="image">
            <img src="static/images/placeholder_dual_layer.png" alt="Primitive and symbolic layers in CUBE" />
          </figure>
          <p class="subtitle is-size-6">
            Symbolic actions unfold into sequences of primitive movements that operate on the shared grid.
          </p>
        </div>

        <div class="column is-half">
          <div class="content has-text-justified">
            <h3 class="title is-5">Observation</h3>
            <p>
              CUBE exposes two complementary observations.
            </p>
            <ul>
              <li>
                <strong>Symbolic observation.</strong>
                Per agent dictionaries that include global grid size, positions of all agents,
                and compact summaries of each block such as id, weight, position, and distance to the goal column.
                The history of symbolic actions, their primitive expansions, and their status
                is also recorded, which supports reasoning about what has been tried so far.
              </li>
              <li>
                <strong>Multi channel observation.</strong>
                A five channel grid with agent locations, block weights, goal column, agent index per cell,
                and block id per cell, intended for reinforcement learning encoders and visualizations.
              </li>
            </ul>

            <h3 class="title is-5">Action</h3>
            <p>
              The action interface has two layers.
            </p>
            <ul>
              <li>
                <strong>Primitive actions.</strong>
                Each agent chooses from <code>{STAY, UP, DOWN, LEFT, RIGHT}</code>.
                Movements succeed only when the target cell is free, and pushes succeed only when aligned agents
                provide enough force and the front cell is empty.
              </li>
              <li>
                <strong>Symbolic actions.</strong>
                A small library of parameterized actions such as
                <code>move</code>, <code>move_to_block</code>, <code>rendezvous</code>,
                <code>push_block</code>, <code>yield_block</code>, <code>idle</code>,
                and <code>wait_agents</code>. Each action compiles to primitive moves until a condition is met.
                Agents submit short plans that are sequences of such actions with arguments, which then execute in order.
              </li>
            </ul>

            <h3 class="title is-5">Feedback and symbolic concepts</h3>
            <p>
              CUBE provides both scalar rewards and a library of symbolic concepts that help define custom metrics.
              The default reward has a small step cost and a shared delivery reward proportional to delivered block weight.
              Symbolic concepts include utilities such as functions that measure distances, count aligned agents,
              summarize block progress, measure quorum deficit, and detect blocking, which can be combined
              to design adaptive feedback or evaluation signals.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Chains and Embodied Failure Modes</h2>

      <p class="content has-text-justified mb-4">
        In CUBE, blocks can form chains that require joint force from several agents.
        A pushing line forms when agents align along a block face, each contributing unit force in the push direction.
        Motion succeeds only when the total applied force meets or exceeds the chain weight and the frontmost
        destination cell is free.
      </p>

      <p class="content has-text-justified mb-5">
        Valid tasks can disappear dynamically as blocks move.
        For example, a face of a block that was previously reachable can vanish when another block moves adjacent
        to it. Agents that were committed to that face must then recover and replan.
        Cell races and boundary geometry introduce further failure cases, such as blocks that become actionless
        along walls because they can only be pushed, not pulled.
      </p>

      <div class="columns is-multiline is-centered is-variable is-2">
        <div class="column is-one-quarter has-text-centered">
          <figure class="image">
            <img src="static/images/x.png" alt="Successful pushing chain with agents aligned" />
          </figure>
          <p class="subtitle is-size-6 mt-2">
            <strong>Successful chain.</strong> Aligned agents form a stable pushing line and move a composite block chain.
          </p>
        </div>

        <div class="column is-one-quarter has-text-centered">
          <figure class="image">
            <img src="static/images/x.png" alt="Geometric failure case" />
          </figure>
          <p class="subtitle is-size-6 mt-2">
            <strong>Geometric failure.</strong> Misalignment or an occupied destination cell prevents progress.
          </p>
        </div>

        <div class="column is-one-quarter has-text-centered">
          <figure class="image">
            <img src="static/images/comp1.png" alt="Dynamics failure case 1" />
          </figure>
          <p class="subtitle is-size-6 mt-2">
            <strong>Failure I.</strong> Agents cannot stage on the target face due to congestion, so no joint push can form.
          </p>
        </div>

        <div class="column is-one-quarter has-text-centered">
          <figure class="image">
            <img src="static/images/comp2.png" alt="Dynamics failure case 2" />
          </figure>
          <p class="subtitle is-size-6 mt-2">
            <strong>Failure II.</strong> Agents block one another or oscillate, preventing stable cooperation despite a feasible strategy.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-vcentered">
          <div class="column is-half">
            <h3 class="title is-3">Controllable Difficulty Curriculum</h3>
            <div class="content has-text-justified">
              <p>
                A single integer <code>n</code> controls the entire task family.
              </p>
              <ul>
                <li>Grid side length set by <code>k = max(20, n)</code>.</li>
                <li><code>n</code> agents placed along the wall opposite the goal region.</li>
                <li>Blocks with weights from <code>⌊n/2⌋ + 1</code> down to one, with lighter blocks appearing more often.</li>
              </ul>
              <p>
                Larger <code>n</code> increases both congestion and the quorum needed to move heavier blocks.
                Layouts at a fixed <code>n</code> differ but have similar cooperative complexity, which provides
                a clear curriculum from small groups to large teams.
              </p>
            </div>
          </div>
          <div class="column is-half has-text-centered">
            <figure class="image">
              <img src="static/images/n5.jpg" alt="Difficulty curriculum controlled by n" />
            </figure>
            <p class="subtitle is-size-6">
              Grid size, agent count, and block distribution scale with the curriculum parameter <em>n</em>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">

        <h2 class="title is-3 has-text-centered">Baselines and Task Performance</h2>

        <div class="columns is-vcentered" style="margin-bottom:2rem;">
          <div class="column is-half">
            <h3 class="title is-4">Heuristic baseline</h3>
            <div class="content has-text-justified">
              <p>
                The heuristic baseline follows a greedy strategy.
                At each stage it selects the block closest to the goal zone and assigns agents to move it,
                issuing symbolic instructions such as <code>move_to_block</code>, <code>rendezvous</code>, and
                <code>push_block</code> until the block is delivered. The baseline produces valid cooperative
                behavior without explicitly optimizing path length or resolving congestion, and serves as a
                reference point for more advanced agents.
              </p>
            </div>
          </div>
          <div class="column is-half has-text-centered">
            <figure class="image">
              <img src="static/images/complete_rate_vs_agents.png" alt="Completed blocks vs number of agents" />
            </figure>
            <p class="subtitle">
              Number of completed blocks versus agent count <em>n</em> for language agents and the heuristic baseline.
            </p>
          </div>
        </div>

        <div class="columns is-vcentered">
          <div class="column is-half">
            <h3 class="title is-4">Naive language agents</h3>
            <div class="content has-text-justified">
              <p>
                As language based baselines, the paper evaluates two LLM agents in a zero shot style setting.
                Each agent repeatedly receives a symbolic observation and generates short plans written in the
                CUBE action vocabulary, with a prompt that encodes a simple rule
                to always target the block closest to the goal zone.
              </p>
              <p>
                These naive LLM agents can generate executable plans but perform inconsistently,
                particularly when they must rely on other agents. Smaller models show high variance and longer runtimes,
                suggesting frequent replanning and difficulty with coordination as n grows.
              </p>
            </div>
          </div>
          <div class="column is-half has-text-centered">
            <figure class="image">
              <img src="static/images/steps_vs_agents.png" alt="Average steps vs n by model" />
            </figure>
            <p class="subtitle">
              Average steps per episode as <em>n</em> increases (capped at 200 steps).
            </p>
            <figure class="image" style="margin-top:1rem;">
              <img src="static/images/runtime_vs_agents.png" alt="Runtime vs n by model" />
            </figure>
            <p class="subtitle">
              Average runtime versus <em>n</em> by model, highlighting that LLM inference dominates runtime.
            </p>
          </div>
        </div>

        <div class="content has-text-justified" style="margin-top:2rem;">
          <p>
            Overall, the heuristic baseline consistently completes all blocks at the tested scales,
            whereas naive LLM agents reveal a cooperation gap. They can express nontrivial symbolic behavior
            yet fall short of robust cooperative performance as team size grows. This motivates richer designs
            for embodied LLM agents that combine symbolic world models, communication, and learning.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Scalability and Computational Overhead</h2>
        <div class="columns is-vcentered">
          <div class="column is-one-third has-text-centered">
            <figure class="image">
              <img src="static/images/mean_time.png" alt="Mean time per step vs agents" />
            </figure>
            <p class="subtitle">
              Mean environment step time grows smoothly with <em>n</em>,
              from small fractions of a millisecond for small teams to tens of milliseconds at 256 agents on one CPU core.
            </p>
          </div>
          <div class="column is-one-third has-text-centered">
            <figure class="image">
              <img src="static/images/memory.png" alt="Process memory usage vs agents" />
            </figure>
            <p class="subtitle">
              Memory usage increases approximately linearly, reaching under a gigabyte at <em>n</em> equal to 256,
              with tens of megabytes at small scales.
            </p>
          </div>
          <div class="column is-one-third has-text-centered">
            <figure class="image">
              <img src="static/images/cpu.png" alt="CPU utilization vs agents" />
            </figure>
            <p class="subtitle">
              CPU utilization rises steadily and stays within a manageable range even with 256 agents,
              so the environment remains lightweight compared with LLM inference.
            </p>
          </div>
        </div>

        <div class="columns is-vcentered" style="margin-top:2rem;">
          <div class="column is-half has-text-centered">
            <figure class="image">
              <img src="static/images/line_chart_performance.png" alt="Runtime vs agents by action type" />
            </figure>
            <p class="subtitle">
              Mean runtime per symbolic action versus agent count.
              Most actions stay in a narrow band of run times even at larger n, while actions that inspect
              many environment objects become more expensive but remain efficient.
            </p>
          </div>
          <div class="column is-half has-text-centered">
            <figure class="image">
              <img src="static/images/heatmap_performance.png" alt="Action runtime heatmap" />
            </figure>
            <p class="subtitle">
              Heatmap of symbolic action runtimes across scales.
            </p>
          </div>
        </div>

        <div class="content has-text-justified" style="margin-top:2rem;">
          <p>
            In contrast, LLM inference time is relatively large. Generating even short plans takes hundreds of milliseconds
            to seconds, which makes environment overhead negligible for studies of embodied language agents.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Challenges and Opportunities</h2>
      <div class="columns">
        <div class="column">
          <h3 class="title is-4">Dynamic scene and task</h3>
          <div class="content has-text-justified">
            <p>
              As agents move blocks they create new chains, tighten corridors, or close off some paths,
              which can make later deliveries easier or harder. Agents must reason about how current
              choices change future task difficulty and may need to revise decompositions on the fly.
            </p>
          </div>

          <h3 class="title is-4">Spatial reasoning</h3>
          <div class="content has-text-justified">
            <p>
              Successful teams need to understand how blocks interact, which sides can be used for approach,
              and how block chains create soft dependencies between tasks. Simple distance based rules
              are often not enough when heavy blocks and narrow passages interact.
            </p>
          </div>

          <h3 class="title is-4">Synchronization</h3>
          <div class="content has-text-justified">
            <p>
              Many pushes require several agents to reach specific faces of a block at similar times.
              Rendezvous and waiting behavior must be coordinated with path planning and congestion,
              and agents need to recover when timing assumptions fail.
            </p>
          </div>
        </div>

        <div class="column">
          <h3 class="title is-4">Collective intelligence under uncertainty</h3>
          <div class="content has-text-justified">
            <p>
              Agents rarely know exactly what teammates will do.
              They must form expectations about others, infer goals from movement, and decide when to wait,
              yield, or reroute. Misjudgments can lock tasks temporarily, such as when a single agent
              stands in the only useful staging cell near a block.
            </p>
          </div>

          <h3 class="title is-4">Asynchronization</h3>
          <div class="content has-text-justified">
            <p>
              Agents may execute plans with different horizons and therefore fall out of sync.
              Centralized planners, decentralized policies, and communication protocols all have to cope with
              this asynchrony and design strategies that are robust to partial or delayed execution.
            </p>
          </div>

          <h3 class="title is-4">Research directions</h3>
          <div class="content has-text-justified">
            <p>
              CUBE opens space for methods that blend symbolic world models, model predictive control,
              multi agent reinforcement learning, and LLM based planning.
              It also supports comparison between centralized planners and decentralized designs that rely on
              communication, emerging conventions, or shared tools for cooperation.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Poster</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="publication-video">
              <iframe src="static/pdfs/cube_poster.pdf" frameborder="0" style="width:100%; height:800px;" allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{yangcube,
  title     = {CUBE: Collaborative Multi-Agent Block-Pushing Environment for Collective Planning with LLM Agents},
  author    = {Yang, Hanqing and Nourzad, Narjes and Chen, Shiyu and Joe-Wong, Carlee},
  booktitle = {Workshop on Scaling Environments for Agents},
  year      = {2025}
}</code>
</pre>
      Please also feel free to check our other work, DR WELL, where decentralized LLM agents cooperate in CUBE.
<pre><code>@inproceedings{nourzad2025dr,
  title={DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration},
  author={Nourzad, Narjes and Yang, Hanqing and Chen, Shiyu and Joe-Wong, Carlee},
  booktitle={NeurIPS 2025 Workshop on Bridging Language, Agent, and World Models for Reasoning and Planning},
  year={2025}
}</code>
</pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the
              <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>,
              adapted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
